<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="AutoOS: Make Your OS More Powerful by Exploiting Large Language Models">
  <meta name="keywords" content="Large language model，OS，linux kernel，optimization">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CodeV: AutoOS: Make Your OS More Powerful by Exploiting Large Language Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <!-- highlight code -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">AutoOS: Make Your OS More Powerful by Exploiting Large Language Models
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a>Huilai Chen</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a>Yuanbo Wen</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a>Limin Cheng</a><sup>3</sup>,</span>
                <span class="author-block">
                  <a>Shouxu Kuang</a><sup>2,3</sup>,</span>
                <span class="author-block">
                  <a>Yumeng Liu</a><sup>3</sup>,</span>
                <span class="author-block">
                  <a>Weijia Li</a><sup>2,3</sup>,</span>
                <span class="author-block">
                  <a>Ling Li</a><sup>3</sup>,</span>
                <span class="author-block">
                  <a>Rui Zhang</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a>Xinkai Song</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a>Wei Li</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a>Qi Guo</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a>Yunji Chen</a><sup>1</sup>
                </span>
              </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>SKL of Processors, Institute of Computing Technology,
                CAS</span><br>
              <span class="author-block"><sup>2</sup>University of Chinese Academy of Sciences</span><br>
              <span class="author-block"><sup>3</sup>Intelligent Software Research Center, Institute of Software</span><br>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://openreview.net/pdf?id=Rp8R9C0Sth" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/xuewuyinhe/AutoOS" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>             
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              With the rapid development of Artificial Intelligence of Things (AIoT), customizing and optimizing operating system (OS) kernel configurations
              for various AIoT application scenarios is crucial for maximizing system performance. However,
              existing approaches falter due to the overwhelming problem complexity (i.e., over 15,000 configuration options in the Linux kernel), together with
              the huge evaluation costs and error-prone options
              that may result in OS boot-up failure, which all
              make it an unresolved problem to optimize the
              Linux kernel automatically. In this paper, we introduce AutoOS, a novel framework exploiting
              Large Language Models for customizing and optimizing OS kernel configurations automatically
              for various AIoT application scenarios. Inspired
              by the inherently directory-structured kernel configuration process, we first formulate our research
              problem as optimizing on a dynamic tree. We
              then propose a novel framework integrating a state
              machine-based traversal algorithm as the observeprune-propose-act-correct loop, which can effectively refine the optimization space and ensure
              a successful OS boot-up. Experimental results
              show that AutoOS can automatically customize
              and optimize the OS kernel configurations without
              human effort. More importantly, AutoOS even
              achieves better performance by up to 25% than
              vendor-provided configuration.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
      <!-- Overview. -->
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Overview</h2>
          <div class="content">
            <p>
              We first collect and filter high-quality Verilog modules
              from open-source codebases. The modules are then sent to GPT-3.5 to request multi-level summaries.
              Pairing high-level descriptions with corresponding modules, the high-quality dataset is utilized to
              fine-tune base LLMs, yielding CodeV models.
            </p>
          </div>
          <img src="./static/images/overview.png">
        </div>
      </div>
      <!--/ Overview. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <h2 class="title is-3"> Multi-level Code Summarization</h2>
            <p>
              Manual annotation is prohibitively time-consuming and costly. Hence, we employed GPT-3.5 to generate high-level summaries for each Verilog module as its requirement description. As analyzed in VerilogEval, when required for summarising, LLMs often produce verbose descriptions, preferring line-by-line explanations over high-level summaries. To address this issue, we introduce a multi-level summarization method, employing few-shot learning to guide GPT-3.5 in first producing detailed descriptions and then abstracting high-level summaries.
            </p>
            <p>
              An actual example of the prompt for multi-level summarization. (a) The prompt provided to GPT-3.5. (b) An example of the demonstrations, with code, low-level descriptions, and high-level summaries. (c) Summaries responded from GPT-3.5 with and (d) without multi-level summarization.
            </p>
            <img src="./static/images/multilevel_sum_demo.png">
            </p>
          </div>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <h2 class="title is-3"> Main Results </h2>
            <p>
              We compares the main results of our CodeV with baseline methods on the VerilogEval and RTLLM benchmarks. We test CodeLlama, DeepSeek-Coder, and CodeQwen on RTLLM, while other baseline results are sourced from RTLCoder or BetterV paper. For a fair comparison, we also evaluate our models trained on comparable-size datasets against RTLCoder.
            </p>
            <p>
              Comparison of our CodeV models against various baseline models. Some data are missing due to the models being close-sourced and the data not being reported previously. The best results are highlighted in bold. In VerilogEval, CodeV outperforms all previous methods across all metrics, relatively surpassing previous open-source SOTA BetterV by 14.4% and GPT-4 by 22.1% on average. In RTLLM, CodeV relatively surpasses previous open-source SOTA RTLCoder by 11.3%.</p>
            <img src="./static/images/result1.png">
            </p>
          </div>
        </div>
      </div>


      <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <h2 class="title is-3"> LLM-generated Verilog code </h2>
            <p>
              We have collected existing LLMs of Verilog code and demonstrated their performance on VerilogEval and RTLLM in
              <a href="https://iprc-dip.github.io/Chip-Design-LLM-Zoo/" target="_blank">Chip Design LLM Zoo</a>.
            </p>
          </div>
        </div>
      </div>

      <!-- Method -->

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Quick Start</h2>
          <pre style="width: 100%; overflow: auto; background: none;">
          <code class="python" style="min-width: 100%; width: 0px; overflow: scroll; font-family: 'Cascadia Code', 'Menlo', 'Courier New', monospace;">
from transformers import pipeline
import torch
prompt= "FILL IN THE QUESTION"
generator = pipeline(
  model="CODEV",
  task="text-generation",
  torch_dtype=torch.bfloat16,
  device_map="auto",
)
result = generator(prompt , max_length=2048,num_return_sequences=1, temperature=0.0)
response = result[0]["generated_text"]
print("Response:", response)
            </code>
          </pre>
        </div>
      </div>
    </div>
  
    <!-- <hr/> -->
    <!-- <section class="section" id="BibTeX"> -->
      <!-- <div class="columns is-centered"> -->
        <div class="container content is-max-desktop">
            <h2 class="title is-3"> BibTex </h2>
              <pre>
  <code class="nohighlight" style="background-color: transparent; color: black; font-family: monospace;">@misc{zhao2024codevempoweringllmsverilog,
    title={CodeV: Empowering LLMs for Verilog Generation through Multi-Level Summarization},
    author={Yang Zhao and Di Huang and Chongxiao Li and Pengwei Jin and Ziyuan Nan and Tianyun Ma and Lei Qi and Yansong Pan and Zhenxing Zhang and Rui Zhang and Xishan Zhang and Zidong Du and Qi Guo and Xing Hu and Yunji Chen},
    year={2024},
    eprint={2407.10424},
    archivePrefix={arXiv},
    primaryClass={cs.PL},
    url={https://arxiv.org/abs/2407.10424},
  }</code>
              </pre>
      </div>
      <!-- </section> -->
  </section>

  <!-- <hr/> -->
  

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              Thanks for the website template <a href="https://nerfies.github.io">Nerfies</a>
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
